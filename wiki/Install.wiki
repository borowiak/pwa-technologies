#summary Install the product from pwa
#labels Phase-Deploy,Featured

==Install Hadoop==

After compiling the product following the instructions of [Compile] there will be a need to create a hadoop cluster to process a large number of arc files. This file has for base the tutorial [http://wiki.apache.org/hadoop/QuickStart], [http://hadoop.apache.org/common/docs/current/cluster_setup.html] and [http://wiki.apache.org/hadoop/GettingStartedWithHadoop].

First you have to grab the files generated by the compile of the hadoop and copy them to your cluster servers.

===Hadoop configuration files===

First you need to configure some files to allow hadoop to run in a distributed way.
You will need to define a server for hadoop master, this server will have the namenode and tasktracker (for more information on hadoop [http://wiki.apache.org/hadoop] and [http://hadoop.apache.org/]).

After knowing what server to use has master define it in the configurations files.
Setup masters at `${HADOOP_HOME}/conf/masters` file:
{{{
master.example.com
}}}
Setup slaves at `${HADOOP_HOME}/conf/slaves` file:
{{{
server1.example.com
server2.example.com
}}}

Edit the file of `${HADOOP_HOME}/conf/hadoop-site.xml`, change the master, the directories path for your system, every option of this file is in `${HADOOP_HOME}/conf/hadoop-default.xml`:
{{{
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
 <property>
   <name>fs.default.name</name>
   <value>master.example.com:9000</value>
 </property>
 <property>
   <name>mapred.job.tracker</name>
   <value>master.example.com:9001</value>
 </property>
 <property>
   <name>dfs.name.dir</name>
   <value>/hadooptemp/hadoopfs/dfs/namenode</value>
 </property>
 <property>
   <name>dfs.data.dir</name>
   <value>/hadooptemp/hadoopfs/dfs/datanode</value>
 </property>
 <property>
   <name>mapred.system.dir</name>
   <value>/hadooptemp/hadoopfs/mapred/system</value>
 </property>
 <property>
   <name>mapred.local.dir</name>
   <value>/hadooptemp/hadoopfs/mapred/local</value>
 </property>
 <property>
   <name>mapred.child.java.opts</name>
   <value>-Xmx6000m</value>
 </property>
  <property>
     <name>hadoop.tmp.dir</name>
     <value>/hadooptemp/tmp/hadoop-${user.name}</value>
  </property>
</configuration>
}}}

Edit JAVA_HOME variable at `${HADOOP_HOME}/conf/hadoop-env.sh`:
{{{
...
export JAVA_HOME=/usr/java/default
...
}}}

Edit files at master and copy for all other machines.

There is also the need to share the ssh public key from the master server to the other servers:
  # generate ssh key: 
{{{
 ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
}}}
  # remove pwd request from localhost:
{{{
 cat ~/.ssh/id_dsa.pub >>> ~/.ssh/authorized_keys
}}}
  # test (if no pwd is requested then it is OK):
{{{
 ssh localhost
}}}
  # Put the key in other machines, repeat for every machine in the cluster.
{{{
ssh-copy-id -i ~/.ssh/id_dsa.pub user@server1.example.com
}}}
  # Create directories:
{{{
mkdir /data/hadoopfs/dfs/namenode/
mkdir /data/hadoopfs/dfs/datanode/
mkdir /data/hadoopfs/mapred/system/
mkdir /data/hadoopfs/mapred/local/
}}}
  # Format the HDFS:
{{{
${HADOOP_HOME}/bin/hadoop namenode -format
}}}
*Note:* If format is aborted then remove directories and format it again:
{{{
rm -rf /data/hadoopfs/dfs/namenode/*
rm -rf /data/hadoopfs/dfs/datanode/*
rm -rf /data/hadoopfs/mapred/system/*
rm -rf /data/hadoopfs/mapred/local/*
}}}

===Using hadoop===
  # Start the hadoop daemons in all machines from the hadoop cluster:
{{{
${HADOOP_HOME}/bin/start-all.sh
}}}
  # See if the services started OK:
{{{
NameNode http://master.example.com:50070/
JobTracker http://master.example.com:50030/
}}}
  # Stop the hadoop deamons:
{{{
${HADOOP_HOME}/bin/stop-all.sh
}}}

==Operating system changes==
===Change the limits for the number of open files===
There is a need to change some parameters for the servers. Because the hadoop system opens a large number of files there is a need to add 2 lines to the file `/etc/security/limits.conf`:
{{{
...
hard nofile 65000
soft nofile 30000
...
}}}

===Set the default charset in the machines===
Change variable LANG in file `/etc/sysconfig/i18n`:
{{{
LANG="pt_PT.ISO-8859-1"
SUPPORTED="en_US.iso885915:en_US:en:pt_PT@euro:pt_PT:pt"
SYSFONT="lat0-sun16"
SYSFONTACM="iso15"
}}}


==Install search system==

===Requirements===
  * Install apache tomcat 5.5.25 [http://archive.apache.org/dist/tomcat/tomcat-5/v5.5.25/bin/apache-tomcat-5.5.25.tar.gz]
  * Get the compilation result of hadoop 0.14.4 instructions in [Compile]

===Install tomcat===
  * To install and configure tomcat this [http://tomcat.apache.org/tomcat-5.5-doc/setup.html documentation] should be followed.

===Configure nutchwax Web application===

Set ${CATALINA_HOME}/webapps/nutchwax/WEB-INF/classes/hadoop-site.xml with:
{{{
<name>searcher.dir</name>
<value>/opt/searcher/scripts</value>
...
<name>wax.host</name>
<value>t4.tomba.fccn.pt:8080/wayback/wayback</value>
}}}
The directory /opt/searcher/scripts should have a file named `search-servers.txt` where the nutch servers are running:
{{{
  t7.tomba.fccn.pt 21111
  t3.tomba.fccn.pt 21111
}}}
===Configure wayback Web application===
Update `${CATALINA_HOME}/webapps/wayback/WEB-INF/wayback.xml` file:
  * The `resourceIndex` maps the arc name and an URL for the arc it self, normally the URL of the arc is served by an http server. The configuration should refer the arcproxy that knows where all the arc files exist.
  * The `remotecollection` is the location of the search for an url. It should be configured with the nutchwax search.
  * The `uriConverter` is used to reply the url to be accessed.
{{{
...
<property name="resourceStore">
<bean class="org.archive.wayback.resourcestore.Http11ResourceStore">
<property name="urlPrefix" value="http://127.0.0.1:8080/arcproxy/arcproxy/" />
...
<property name="resourceIndex">
<bean class="org.archive.wayback.resourceindex.NutchResourceIndex" init-method="init">
<property name="searchUrlBase" value="http://127.0.0.1:8080/nutchwax/opensearch" />
...
<property name="uriConverter">
<bean class="org.archive.wayback.archivalurl.ArchivalUrlResultURIConverter">
<property name="replayURIPrefix" value="http://MACHINE:8080/wayback/wayback/" />
...
}}}

===Configure arcproxy Web application===

Update ${CATALINA_HOME}/webapps/arcproxy/WEB-INF/wayback.xml file:
  * Change the `bdbPath`, `bdbName` and `logPath` to the parameters to your desire, the directories should be writable.
{{{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE beans PUBLIC "-//SPRING//DTD BEAN//EN" "http://www.springframework.org/dtd/spring-beans.dtd">
<beans>

<!--
    The following 3 beans are required when using the ArcProxy for providing 
    HTTP 1.1 remote access to ARC files distributed across multiple computers 
    or directories.
-->
 
	<bean id="filelocationdb" class="org.archive.wayback.resourcestore.http.FileLocationDB"
		init-method="init">
		<property name="bdbPath" value="/opt/searcher/arcproxy" />
		<property name="bdbName" value="arquivo" />
		<property name="logPath" value="/opt/searcher/arcproxy/tmp_arc-db.log" />
	</bean>

	<bean name="8080:arcproxy" class="org.archive.wayback.resourcestore.http.ArcProxyServlet">
		<property name="locationDB" ref="filelocationdb" />
	</bean>
	<bean name="8080:locationdb" class="org.archive.wayback.resourcestore.http.FileLocationDBServlet">
		<property name="locationDB" ref="filelocationdb" />
	</bean>

</beans>
}}}

===Configure browser Web application===

==Install Search System==

For this you have to use the jar and the hadoop folder after [Compile] has been run.

  * Copy the folder of hadoop to the server that will serve the collection. For each collection you will need a new copy of this folder.
  * Get the scripts from `svn checkout http://pwa-technologies.googlecode.com/svn/trunk/scripts`
  * Define a `COLLECTIONS_DIR` with the folder of the location of the file `search-servers.txt`.
  * Define a 




